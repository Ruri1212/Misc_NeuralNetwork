{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SsoE3T4HMZv"
      },
      "source": [
        "# 応用情報工学演習（谷口研）深層学習ベースの画像認識 深層学習の基本 - Google Colab -\n",
        "\n",
        "今回から応用的なPyTorchの使い方について確認していきます。GPUを利用しないと時間がかかるため、PyTorch 1回目のドキュメントを参照して、GPUランタイムを使うようにしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sq7LWW1GyMr"
      },
      "source": [
        "## MNISTデータ\n",
        "\n",
        "Modified National Institute of Standards and Technology database (MNIST) と呼ばれるデータセットを利用した数字認識をニューラルネットワークによって行います。\n",
        "\n",
        "MNISTは、様々なパターンの手書き数字が、訓練用に6万枚、検証用に1万枚用意されています。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1twT3PKPpfyZ7Oi3D1jxA9BBd8YmW13_L\">\n",
        "\n",
        "機械学習・ディープラーニングプログラミングでよく利用される、代表的なデータセットです。\n",
        "\n",
        "ディープラーニングを使わずSupport Vector Machine (SVM) などの従来型の機械学習モデルでも97~98%の精度であることが良く知られており、\n",
        "あたらしく作成したモデルが著しく低い精度を示す場合、何かおかしいといったことに気がつくためのデバッグ的利用が多いです。\n",
        "\n",
        "近年では、簡単過ぎるため、実際の精度評価には後述のCIFAR-10など、別のデータセットが使用されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9D64CFTTWHv"
      },
      "source": [
        "***ライブラリのインポート***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIKc0rgJQRbQ"
      },
      "outputs": [],
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4AKptKEQRbQ"
      },
      "outputs": [],
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaJvhUX1QRbR"
      },
      "outputs": [],
      "source": [
        "# warning表示off\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuXnWk6jtpfW"
      },
      "source": [
        "## GPU利用\n",
        "\n",
        "Google Colab上ではGPUが利用できます。\n",
        "\n",
        "PyTorchでは、データがCPU、GPUのどちらにあるかを常に意識する必要があります。\n",
        "\n",
        "GPUを利用する場合のプログラミング手法を確認します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9dK3ibfzWDW"
      },
      "source": [
        "### GPUチェック\n",
        "\n",
        "cuda:0と表示されれば成功。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vMUHy9RGyNB"
      },
      "outputs": [],
      "source": [
        "# デバイスの割り当て\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j915qVD5HMZ5"
      },
      "source": [
        "### GPU利用のルール\n",
        "\n",
        "PyTorchでGPUを利用する場合のルールは次の通りです。\n",
        "\n",
        "* テンソル変数はデータがCPU／GPU上のどちらにあるかを属性として持っている。\n",
        "* CPUとGPU間でデータはto関数で転送する\n",
        "* 2つの変数が両方ともGPU上にある場合、演算はGPUで行われる\n",
        "* 変数の片方がCPU、もう一方がGPUの場合、演算はエラーになる\n",
        "\n",
        "以下のサンプルでこのことを試してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-koKiUTy8fx"
      },
      "outputs": [],
      "source": [
        "# テスト用tensor変数x , y\n",
        "x_np = np.arange(-2.0, 2.1, 0.25)\n",
        "y_np = np.arange(-1.0, 3.1, 0.25)\n",
        "x = torch.tensor(x_np).float()\n",
        "y = torch.tensor(y_np).float()\n",
        "\n",
        "# xとyの間の演算\n",
        "z = x * y\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-VBUQL135T3"
      },
      "outputs": [],
      "source": [
        "# 変数xをGPUに送る\n",
        "x = x.to(device)\n",
        "\n",
        "# 変数xとyの属性data, deviceの確認\n",
        "print('x: ', x.device)\n",
        "print('y: ', y.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovOqHX2735yN"
      },
      "outputs": [],
      "source": [
        "# この状態でxとyの演算をすると。。。\n",
        "\n",
        "try :\n",
        "  z = x * y\n",
        "except Exception as e:\n",
        "  print(\"ERROR:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qavPREnP359u"
      },
      "outputs": [],
      "source": [
        "# yもGPUに送る\n",
        "y = y.to(device)\n",
        "\n",
        "# 今度は計算可能になる\n",
        "z = x * y\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S2H468hORq2"
      },
      "source": [
        "## データ前処理\n",
        "\n",
        "学習データをモデルへ入力する前に加工することをデータ前処理といいます。\n",
        "\n",
        "PyTorchではtorchvision.transformsというライブラリに、前処理に便利な部品がそろっていて、この部品を組み合わせて使うだけで、簡単に望む形式へのデータ変換できます。\n",
        "\n",
        "機械学習ではデータの収集も重要な準備です。こちらも便利な仕組みが用意されています（後述）。\n",
        "\n",
        "PyTorchで用意されているデータを利用して、まずはデータ前処理の方法を確認します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLtoL2DRHMZ7"
      },
      "source": [
        "### (前処理1) Datasetによるデータ読み込み\n",
        "\n",
        "Datasetというクラスを利用することで、[様々なデータ](https://pytorch.org/vision/stable/datasets.html)を取得することができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbjBR_ZAORq3"
      },
      "outputs": [],
      "source": [
        "# ライブラリインポート\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# ダウンロード先ディレクトリ名\n",
        "data_root = './data'\n",
        "\n",
        "train_set0 = datasets.MNIST(\n",
        "    # 元データダウンロード先の指定\n",
        "    root = data_root,\n",
        "    # 訓練データか検証データか\n",
        "    train = True,\n",
        "    # 元データがない場合にダウンロードするか\n",
        "    download = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZDvzf2nSc8n"
      },
      "outputs": [],
      "source": [
        "# ダウンロードしたファイルの確認\n",
        "\n",
        "!ls -lR ./data/MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTnvCClZh93k"
      },
      "outputs": [],
      "source": [
        "# データ件数の確認\n",
        "print('データ件数: ', len(train_set0))\n",
        "\n",
        "# 最初の要素の取得\n",
        "image, label = train_set0[0]\n",
        "\n",
        "# データ型の確認\n",
        "print('入力データの型: ', type(image))\n",
        "print('正解データの型: ', type(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zax7TjeCORq5"
      },
      "outputs": [],
      "source": [
        "# 入力データの画像表示\n",
        "\n",
        "plt.figure(figsize=(2,3))\n",
        "plt.title(f'{label}')\n",
        "plt.imshow(image, cmap='gray_r')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cltigf4xh95z"
      },
      "outputs": [],
      "source": [
        "# 正解データ付きで、最初の20個をイメージ表示\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(20):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "\n",
        "    # image と labelの取得\n",
        "    image, label = train_set0[i]\n",
        "\n",
        "    # イメージ表示\n",
        "    plt.imshow(image, cmap='gray_r')\n",
        "    ax.set_title(f'{label}')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H69fmQI0ORq6"
      },
      "source": [
        "### (前処理2) Transformsによるデータ前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_LMC1gpORq6"
      },
      "source": [
        "**Step1 ToTensorの利用**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JBDhjnIORq6"
      },
      "outputs": [],
      "source": [
        "# ライブラリインポート\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform1 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_set1 = datasets.MNIST(\n",
        "    root=data_root,  train=True,  download=True,\n",
        "    transform = transform1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHERq6bDORq6"
      },
      "outputs": [],
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set1[0]\n",
        "print('入力データの型: ', type(image))\n",
        "print('入力データのshape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc0HYDp_ORq7"
      },
      "source": [
        "**Step2 Normalizeの利用**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGCtROV8ORq7"
      },
      "outputs": [],
      "source": [
        "transform2 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # データの正規化\n",
        "    transforms.Normalize(0.5,  0.5),\n",
        "])\n",
        "\n",
        "train_set2 = datasets.MNIST(\n",
        "    root = data_root,  train = True,  download = True,\n",
        "    transform = transform2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0R6AO1BORq7"
      },
      "outputs": [],
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set2[0]\n",
        "print('shape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3cZ9aT9ORq8"
      },
      "source": [
        "**Step3 Lambdaを利用して1階テンソル化**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsZ1B1MXORq8"
      },
      "outputs": [],
      "source": [
        "transform3 = transforms.Compose([\n",
        "    # データのTensor化\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # データの正規化\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "\n",
        "    # Tensorの1階テンソル化\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "train_set3 = datasets.MNIST(\n",
        "    root = data_root,  train = True,\n",
        "    download=True, transform = transform3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQFnaPTnORq8"
      },
      "outputs": [],
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "image, label = train_set3[0]\n",
        "print('shape: ', image.shape)\n",
        "print('最小値: ', image.data.min())\n",
        "print('最大値: ', image.data.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm2hP2TtORq9"
      },
      "source": [
        "**最終的な実装**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LuXsts3ORq9"
      },
      "outputs": [],
      "source": [
        "# データ変換用関数 Transforms\n",
        "# (1) Imageをテンソル化\n",
        "# (2) [0, 1]の範囲の値を[-1, 1]の範囲にする\n",
        "# (3) データのshapeを[1, 28, 28]から[784]に変換\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # (1) データのテンソル化\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # (2) データの正規化\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "\n",
        "    # (3) 1階テンソルに変換\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gEppo6VORq9"
      },
      "outputs": [],
      "source": [
        "# データ取得用関数 Dataset\n",
        "\n",
        "# 訓練用データセットの定義\n",
        "train_set = datasets.MNIST(\n",
        "    root = data_root, train = True,\n",
        "    download = True, transform = transform)\n",
        "\n",
        "# 検証データセットの定義\n",
        "test_set = datasets.MNIST(\n",
        "    root = data_root, train = False,\n",
        "    download = True, transform = transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE2YPjEFORq-"
      },
      "source": [
        "### (前処理3) データローダーによるミニバッチ用データ生成\n",
        "\n",
        "勾配降下法で学習する場合、何件のデータで勾配計算をするかという問題があります。\n",
        "\n",
        "一般的に学習データは多ければ多いほどよい学習結果が得られます。学習データが数万あるというのも珍しくありません。\n",
        "実際、今回利用するMNISTも6万件のデータがあります。\n",
        "\n",
        "一つずつ勾配を計算すると時間がかかるため、いくらかまとめて計算することを考えます。\n",
        "\n",
        "事前に決めた数でグループを作り、このグループ単位で勾配計算をする方法を`ミニバッチ学習法`と呼びます。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CC6E0a5fHIs-n4Av7OTMO1uMc6mKhnJL\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Jog4MHORq-"
      },
      "outputs": [],
      "source": [
        "# ライブラリインポート\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ミニバッチのサイズ指定\n",
        "batch_size = 500\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size = batch_size,\n",
        "    shuffle = True)\n",
        "\n",
        "# 検証用データローダー\n",
        "# 検証時にシャッフルは不要\n",
        "test_loader = DataLoader(\n",
        "    test_set,  batch_size = batch_size,\n",
        "    shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpWvs4n9ORq-"
      },
      "outputs": [],
      "source": [
        "# 何組のデータが取得できるか\n",
        "print(len(train_loader))\n",
        "\n",
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIk15hXpORq_"
      },
      "outputs": [],
      "source": [
        "# イメージ表示\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(20):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "\n",
        "    # numpyに変換\n",
        "    image = images[i].numpy()\n",
        "    label = labels[i]\n",
        "\n",
        "    # imgの範囲を[0, 1]に戻す\n",
        "    image2 = (image + 1)/ 2\n",
        "    # イメージ表示\n",
        "    plt.imshow(image2.reshape(28, 28),cmap='gray_r')\n",
        "    ax.set_title(f'{label}')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C68aEOhrGyNA"
      },
      "source": [
        "全体で60,000件ある訓練データが120個のグループに分割されて取得できていることがわかります。\n",
        "\n",
        "今回はテスト用でシャッフルなしでデータを取得しましたが、訓練データは取得のたびにシャッフルがかかります。\n",
        "\n",
        "つまり、ミニバッチ用のデータセットが自動的に取得できていることになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBHL-ynpTx6X"
      },
      "source": [
        "## ニューラルネットワーク\n",
        "\n",
        "線形層、あるいは全結合層を積み重ねたモデルをニューラルネットワーク（多層パーセプトロン）と呼び、層の数が多いものを特に深層学習（Deep Learning）と呼びます。\n",
        "\n",
        "ヒトの神経細胞（ニューロン）ネットワークの仕組みを模しているため、人工知能（AI：Artificial Intelligence）と呼称されることもあります。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mLX035DoahddOQbmEHRq462w2ug7OZvz\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vlvZjd_y8fw"
      },
      "source": [
        "### 活性化関数\n",
        "\n",
        "ニューラルネットワークで重要な計算に`活性化関数`というものがあります。\n",
        "\n",
        "これまでに扱った線形層をいくら重ねても線形関数にしかならないことが知られています。\n",
        "\n",
        "活性化関数は、階層の深いニューラルネットワークを意味あるものにするために、線形関数の計算結果に対して非線形作用を与えます。\n",
        "\n",
        "以下ではよく利用されるReLU関数を紹介しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_avlPTrRHMaA"
      },
      "source": [
        "**ReLU関数**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr0e6fNJztAr"
      },
      "outputs": [],
      "source": [
        "# ReLU関数のグラフ\n",
        "\n",
        "relu = nn.ReLU()\n",
        "x_np = np.arange(-2, 2.1, 0.25)\n",
        "x = torch.tensor(x_np).float()\n",
        "y = relu(x)\n",
        "\n",
        "plt.plot(x.data, y.data)\n",
        "plt.title('ReLU')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPlNbYNUHMaA"
      },
      "source": [
        "### ニューラルネットワークの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIXhfySWTx6Y"
      },
      "outputs": [],
      "source": [
        "# 入力次元数\n",
        "n_input = image.shape[0]\n",
        "\n",
        "# 出力次元数\n",
        "# 分類先クラス数　今回は10になる\n",
        "n_output = len(set(list(labels.data.numpy())))\n",
        "\n",
        "#   隠れ層のノード数\n",
        "n_hidden = 128\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_hidden: {n_hidden} n_output: {n_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIHt22OFGyNC"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# 784入力10出力1隠れ層のニューラルネットワークモデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output, n_hidden):\n",
        "        super().__init__()\n",
        "\n",
        "        # 隠れ層の定義 (隠れ層のノード数: n_hidden)\n",
        "        self.l1 = nn.Linear(n_input, n_hidden)\n",
        "\n",
        "        # 出力層の定義\n",
        "        self.l2 = nn.Linear(n_hidden, n_output)\n",
        "\n",
        "        # ReLU関数の定義\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        x2 = self.relu(x1)\n",
        "        x3 = self.l2(x2)\n",
        "        return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE5l-chbGyND"
      },
      "outputs": [],
      "source": [
        "# 訓練データセット　最初の1項目を取得\n",
        "# データローダーから最初の1セットを取得する\n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "\n",
        "# 乱数の固定化\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = Net(n_input, n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# オプティマイザ: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8e4FfOLfFV4"
      },
      "outputs": [],
      "source": [
        "# tqdmライブラリのインポート\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_acc, train_loss = 0, 0\n",
        "    val_acc, val_loss = 0, 0\n",
        "    n_train, n_test = 0, 0\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        n_train += len(labels)\n",
        "\n",
        "        # GPUヘ転送\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #勾配の初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 予測計算\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # 損失計算\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 勾配計算\n",
        "        loss.backward()\n",
        "\n",
        "        # パラメータ修正\n",
        "        optimizer.step()\n",
        "\n",
        "        # 予測ラベル導出\n",
        "        predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "        # 損失と精度の計算\n",
        "        train_loss += loss.item()\n",
        "        train_acc += (predicted == labels).sum()\n",
        "\n",
        "    #予測フェーズ\n",
        "    for inputs_test, labels_test in test_loader:\n",
        "        n_test += len(labels_test)\n",
        "\n",
        "        inputs_test = inputs_test.to(device)\n",
        "        labels_test = labels_test.to(device)\n",
        "\n",
        "\n",
        "        # 予測計算\n",
        "        outputs_test = net(inputs_test)\n",
        "\n",
        "        # 損失計算\n",
        "        loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "        #予測ラベル導出\n",
        "        predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "        # 損失と精度の計算\n",
        "        val_loss +=  loss_test.item()\n",
        "        val_acc +=  (predicted_test == labels_test).sum()\n",
        "\n",
        "    # 評価値の算出・記録\n",
        "    train_acc = train_acc / n_train\n",
        "    val_acc = val_acc / n_test\n",
        "    train_loss = train_loss * batch_size / n_train\n",
        "    val_loss = val_loss * batch_size / n_test\n",
        "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "    item = np.array([epoch+1 , train_loss, train_acc.cpu(), val_loss, val_acc.cpu()])\n",
        "    history = np.vstack((history, item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YpNqlm2vZC0"
      },
      "source": [
        "### 結果確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NQJM_UBli5m"
      },
      "outputs": [],
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'[初期状態] loss: {history[0,3]:.5f}, accuracy: {history[0,4]:.5f}' )\n",
        "print(f'[最終状態] loss: {history[-1,3]:.5f}, accuracy: {history[-1,4]:.5f}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phCQdH7No5Z_"
      },
      "outputs": [],
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (9,8)\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='training')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='validation')\n",
        "plt.xlabel('Epoc')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Learning curve (loss)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3I8Jw0ticf2"
      },
      "outputs": [],
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (9,8)\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='training')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='validation')\n",
        "plt.xlabel('Epoc')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Learning curve (accuracy)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHbKGRzI9XWn"
      },
      "source": [
        "**イメージ表示で確認**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVuuBxXWHNvE"
      },
      "outputs": [],
      "source": [
        "# DataLoaderから最初の1セットを取得する\n",
        "for images, labels in test_loader:\n",
        "    break\n",
        "\n",
        "# 予測結果の取得\n",
        "inputs = images.to(device)\n",
        "labels = labels.to(device)\n",
        "outputs = net(inputs)\n",
        "predicted = torch.max(outputs, 1)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN5MGTud7bsf"
      },
      "outputs": [],
      "source": [
        "# 最初の50件でイメージを「正解値:予測値」と表示\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(50):\n",
        "  ax = plt.subplot(5, 10, i + 1)\n",
        "\n",
        "  # numpyに変換\n",
        "  image = images[i]\n",
        "  label = labels[i]\n",
        "  pred = predicted[i]\n",
        "  if (pred == label):\n",
        "    c = 'k'\n",
        "  else:\n",
        "    c = 'b'\n",
        "\n",
        "  # imgの範囲を[0, 1]に戻す\n",
        "  image2 = (image + 1)/ 2\n",
        "\n",
        "  # イメージ表示\n",
        "  plt.imshow(image2.reshape(28, 28),cmap='gray_r')\n",
        "  ax.set_title(f'{label}:{pred}', c=c)\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fvpgxh_dRGh"
      },
      "source": [
        "## 畳み込みニューラルネットワーク\n",
        "\n",
        "畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）は、画像データを扱う際によく用いられるニューラルネットワークです。\n",
        "\n",
        "特徴として`畳み込み層`と`プーリング層`により、画素間の近傍関係を保持して学習することができます。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rOoe4-ZON-SpyG4dzz1eaaiIdgpnnfaN\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2MVQTtrHMaE"
      },
      "source": [
        "### 畳み込み層\n",
        "\n",
        "畳み込み層は、3×3や5×5などの小さな正方形領域（カーネル）を対象画像に少しずつずらしながら掛け合わせる演算をします。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1_d2ySG0rft6OywwDhcD3GXZ2O4ljW-4X\">\n",
        "\n",
        "畳み込みも行列演算の1つなので誤差逆伝播可能で、カーネルの形を学習します。\n",
        "\n",
        "その結果、特定の（フィルタに似た）パターンに強く反応するフィルタを作ることができます。\n",
        "\n",
        "PyTorchでは、レイヤー関数として[nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)が用意されています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMXgttAHMaE"
      },
      "source": [
        "### プーリング層\n",
        "\n",
        "プーリング層は、近傍（例: 3x3の範囲）の値を最大値や平均を取ることで1つにまとめる処理をします。\n",
        "\n",
        "位置のズレが起きてもほぼ同じ出力になるため、位置ずれに頑健にする処理と言えます。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1sk4MdUMRozvyLqKvrJzLARGAW28PYrpm\">\n",
        "\n",
        "PyTorchでは、レイヤー関数として[nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)が用意されています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNt0_LhJ18l1"
      },
      "source": [
        "### nn.Flatten\n",
        "\n",
        "学習層ではありませんが、CNNを実装する際に必要になる[nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)について紹介します。\n",
        "\n",
        "`nn.Flatten`は、畳み込み処理やプーリング処理の最中は3階テンソルの形で扱われていたデータを、線形関数（全結合層）`nn.Linear`で扱えるよう、1階テンソルの形に変形します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s-bcZO9rLYI"
      },
      "source": [
        "## 共通関数の定義\n",
        "\n",
        "これ以降は、コードが複雑になるため、よく使う関数を共通関数として定義して使うようにします。内容には目を通して、説明できるようにしましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToVuFBXFoLyJ"
      },
      "source": [
        "### eval_loss 損失計算用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJXCs6L-rRnQ"
      },
      "outputs": [],
      "source": [
        "# 損失計算用\n",
        "def eval_loss(loader, device, net, criterion):\n",
        "\n",
        "    # データローダーから最初の1セットを取得する\n",
        "    for images, labels in loader:\n",
        "        break\n",
        "\n",
        "    # デバイスの割り当て\n",
        "    inputs = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    #  損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JZMOe4roSIe"
      },
      "source": [
        "### fit 学習用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yUPrnCOrRxd"
      },
      "outputs": [],
      "source": [
        "# 学習用関数\n",
        "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
        "\n",
        "    # tqdmライブラリのインポート\n",
        "    from tqdm.notebook import tqdm\n",
        "\n",
        "    base_epochs = len(history)\n",
        "\n",
        "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        #訓練フェーズ\n",
        "        net.train()\n",
        "        count = 0\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            count += len(labels)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 勾配の初期化\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 予測計算\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # 損失計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # 勾配計算\n",
        "            loss.backward()\n",
        "\n",
        "            # パラメータ修正\n",
        "            optimizer.step()\n",
        "\n",
        "            # 予測値算出\n",
        "            predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "            # 正解件数算出\n",
        "            train_acc += (predicted == labels).sum()\n",
        "\n",
        "            # 損失と精度の計算\n",
        "            avg_train_loss = train_loss / count\n",
        "            avg_train_acc = train_acc / count\n",
        "\n",
        "        #予測フェーズ\n",
        "        net.eval()\n",
        "        count = 0\n",
        "\n",
        "        for inputs, labels in test_loader:\n",
        "            count += len(labels)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 予測計算\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # 損失計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # 予測値算出\n",
        "            predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "            # 正解件数算出\n",
        "            val_acc += (predicted == labels).sum()\n",
        "\n",
        "            # 損失と精度の計算\n",
        "            avg_val_loss = val_loss / count\n",
        "            avg_val_acc = val_acc / count\n",
        "\n",
        "        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {avg_train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
        "        item = np.array([epoch+1, avg_train_loss, avg_train_acc.cpu(), avg_val_loss, avg_val_acc.cpu()])\n",
        "        history = np.vstack((history, item))\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80Hew-I7oZA0"
      },
      "source": [
        "### eval_history 学習ログ解析用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlOBN2SzrR2e"
      },
      "outputs": [],
      "source": [
        "# 学習ログ解析\n",
        "\n",
        "def evaluate_history(history):\n",
        "    #損失と精度の確認\n",
        "    print(f'[初期状態] loss: {history[0,3]:.5f}, accuracy: {history[0,4]:.5f}')\n",
        "    print(f'[最終状態] loss: {history[-1,3]:.5f}, accuracy: {history[-1,4]:.5f}' )\n",
        "\n",
        "    num_epochs = len(history)\n",
        "    unit = num_epochs / 10\n",
        "\n",
        "    # 学習曲線の表示 (損失)\n",
        "    plt.figure(figsize=(9,8))\n",
        "    plt.plot(history[:,0], history[:,1], 'b', label='training')\n",
        "    plt.plot(history[:,0], history[:,3], 'k', label='validation')\n",
        "    plt.xticks(np.arange(0,num_epochs+1, unit))\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Learning curve (loss)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # 学習曲線の表示 (精度)\n",
        "    plt.figure(figsize=(9,8))\n",
        "    plt.plot(history[:,0], history[:,2], 'b', label='training')\n",
        "    plt.plot(history[:,0], history[:,4], 'k', label='validation')\n",
        "    plt.xticks(np.arange(0,num_epochs+1,unit))\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Learning curve (accuracy)')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ai6zUiMrg6"
      },
      "source": [
        "### show_images_labels イメージとラベルの表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eocXPBeJM0JU"
      },
      "outputs": [],
      "source": [
        "# イメージとラベル表示\n",
        "def show_images_labels(loader, classes, net, device):\n",
        "\n",
        "    # データローダーから最初の1セットを取得する\n",
        "    for images, labels in loader:\n",
        "        break\n",
        "    # 表示数は50個とバッチサイズのうち小さい方\n",
        "    n_size = min(len(images), 50)\n",
        "\n",
        "    if net is not None:\n",
        "      # デバイスの割り当て\n",
        "      inputs = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # 予測計算\n",
        "      outputs = net(inputs)\n",
        "      predicted = torch.max(outputs,1)[1]\n",
        "      #images = images.to('cpu')\n",
        "\n",
        "    # 最初のn_size個の表示\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    for i in range(n_size):\n",
        "        ax = plt.subplot(5, 10, i + 1)\n",
        "        label_name = classes[labels[i]]\n",
        "        # netがNoneでない場合は、予測結果もタイトルに表示する\n",
        "        if net is not None:\n",
        "          predicted_name = classes[predicted[i]]\n",
        "          # 正解かどうかで色分けをする\n",
        "          if label_name == predicted_name:\n",
        "            c = 'k'\n",
        "          else:\n",
        "            c = 'b'\n",
        "          ax.set_title(label_name + ':' + predicted_name, c=c, fontsize=20)\n",
        "        # netがNoneの場合は、正解ラベルのみ表示\n",
        "        else:\n",
        "          ax.set_title(label_name, fontsize=20)\n",
        "        # TensorをNumPyに変換\n",
        "        image_np = images[i].numpy().copy()\n",
        "        # 軸の順番変更 (channel, row, column) -> (row, column, channel)\n",
        "        img = np.transpose(image_np, (1, 2, 0))\n",
        "        # 値の範囲を[-1, 1] -> [0, 1]に戻す\n",
        "        img = (img + 1)/2\n",
        "        # 結果表示\n",
        "        plt.imshow(img)\n",
        "        ax.set_axis_off()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgu8HwD2om0T"
      },
      "source": [
        "### torch_seed 乱数固定用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j7Pxb2fosMD"
      },
      "outputs": [],
      "source": [
        "# PyTorch乱数固定用\n",
        "\n",
        "def torch_seed(seed=123):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10HShejedqrH"
      },
      "source": [
        "\n",
        "## CIFAR-10\n",
        "\n",
        "MNISTよりも難しいデータとしてCIFAR-10と呼ばれる機械学習用イメージ学習データを利用します。\n",
        "\n",
        "CIFAR-10は、画素数32×32のカラーイメージデータが、airplane、automobile、birdなど10種類のカテゴリに分けられていて、イメージからカテゴリを予測する分類問題の学習データとしてよく用いられます。  \n",
        "訓練用5万枚、検証用として1万枚のデータが含まれています。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=11oJ0VYdP0NNePgBk4DS5_JC1I-tyHF7R\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Hy39-cOhYp"
      },
      "source": [
        "## CNNの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7TkRHKcG5sM"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, n_output, n_hidden):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "    self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d((2,2))\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.l1 = nn.Linear(6272, n_hidden)\n",
        "    self.l2 = nn.Linear(n_hidden, n_output)\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "        self.conv1,\n",
        "        self.relu,\n",
        "        self.conv2,\n",
        "        self.relu,\n",
        "        self.maxpool)\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "       self.l1,\n",
        "       self.relu,\n",
        "       self.l2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.features(x)\n",
        "    x2 = self.flatten(x1)\n",
        "    x3 = self.classifier(x2)\n",
        "    return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFnmwtPQdlTP"
      },
      "outputs": [],
      "source": [
        "# Transformsの定義\n",
        "\n",
        "# transformer2 正規化のみ実施\n",
        "\n",
        "# 検証データ用 : 正規化のみ実施\n",
        "transform2 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "])\n",
        "\n",
        "# データ取得用関数 Datasets\n",
        "data_root = './data'\n",
        "\n",
        "# 訓練データセット 3階テンソル版\n",
        "train_set2 = datasets.CIFAR10(\n",
        "    root =  data_root, train = True,\n",
        "    download = True, transform = transform2)\n",
        "\n",
        "# 検証データセット 3階テンソル版\n",
        "test_set2 = datasets.CIFAR10(\n",
        "    root = data_root, train = False,\n",
        "    download = True, transform = transform2)\n",
        "\n",
        "image2, label2 = train_set2[0]\n",
        "\n",
        "print(image2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuFu7dAqT2Rx"
      },
      "outputs": [],
      "source": [
        "# データローダーの定義\n",
        "\n",
        "# ミニバッチのサイズ指定\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "# 訓練用データローダー\n",
        "# 訓練用なので、シャッフルをかける\n",
        "train_loader2 = DataLoader(train_set2, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 検証用データローダー\n",
        "# 検証時にシャッフルは不要\n",
        "test_loader2 = DataLoader(test_set2,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# train_loader2から1セット取得\n",
        "for images2, labels2 in train_loader2:\n",
        "    break\n",
        "\n",
        "# それぞれのshape確認\n",
        "print(images2.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAsMtbpgPZdD"
      },
      "outputs": [],
      "source": [
        "# 正解ラベル定義\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# 検証データ最初の50個の表示\n",
        "show_images_labels(test_loader2, classes, None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaNLwkXVQYhs"
      },
      "source": [
        "### 学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxqgLqwHb-_"
      },
      "outputs": [],
      "source": [
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# 入力次元数 今回は3*32*32=3072\n",
        "n_input = image2.view(-1).shape[0]\n",
        "\n",
        "# 出力次元数\n",
        "# 分類先クラス数　今回は10になる\n",
        "n_output = len(set(list(labels2.data.numpy())))\n",
        "\n",
        "# 隠れ層のノード数\n",
        "n_hidden = 128\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_hidden: {n_hidden} n_output: {n_output}')\n",
        "\n",
        "# モデルインスタンス生成\n",
        "net = CNN(n_output, n_hidden).to(device)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10\n",
        "\n",
        "# 評価結果記録用\n",
        "history2 = np.zeros((0,5))\n",
        "\n",
        "# 学習\n",
        "history2 = fit(net, optimizer, criterion, num_epochs, train_loader2, test_loader2, device, history2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t12Ii85iQd0j"
      },
      "source": [
        "### 評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSGQXebxS5mP"
      },
      "outputs": [],
      "source": [
        "# 評価\n",
        "\n",
        "evaluate_history(history2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WesZnfA2URl"
      },
      "outputs": [],
      "source": [
        "# 最初の50個の表示\n",
        "\n",
        "show_images_labels(test_loader2, classes, net, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUeYFFtAHMaI"
      },
      "source": [
        "## 過学習\n",
        "\n",
        "モデルが学習データに過度に適応してしまうことを過学習と呼びます。\n",
        "\n",
        "パラメータ数の多い（層の数が多い、ニューロンの数が多い）ネットワークで起こりやすいとされます。\n",
        "\n",
        "過学習の例：  \n",
        "訓練での損失は減少しているが、検証では逆に損失が上昇している。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uTCCwMcBalezSA3tezrP_yhV_gQ_MlSW\" width=40%>\n",
        "\n",
        "過学習を防ぐ手法として、Dropout、Data Augmentationなどが利用されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKVzBNx5HMaI"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "`Dropout`は、学習中に指定した層のニューロンの内ランダムに$p$%の出力を0にする処理です。$p=50$がよく用いられます。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1UyrqM02CVEn0pdUEUklnPX4WSfnRlZ0R\" width=40%>\n",
        "\n",
        "PyTorchでは、[nn.Dropout(0.5)](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)で提供されています。\n",
        "\n",
        "`Dropout`は学習時のみ必要なため、推論時はオフ（すべての出力を通す）にします。\n",
        "\n",
        "PyTorchでは、\n",
        "\n",
        "```python\n",
        "net.train()\n",
        "```\n",
        "\n",
        "で、有効化、\n",
        "\n",
        "```python\n",
        "net.eval()\n",
        "```\n",
        "\n",
        "で無効化することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYG8ZRRnHMaI"
      },
      "source": [
        "### Data Augmentation\n",
        "\n",
        "Data Augmentationはデータ拡張とも呼ばれます。\n",
        "\n",
        "学習用画像にランダムに反転，回転，切り取り，拡大縮小等を加えて学習用画像枚数を水増しします。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1cmjEojxAKs4BWg2W4JZLQEAWPMCE7D6u\" width=40%>\n",
        "\n",
        "モデルからみると繰り返しのたびに異なるパターンのデータが入力されるため、過学習が起きにくくなるとされます。\n",
        "\n",
        "PyTorchでは、Transformsから簡単に利用することができます。以下のコードはランダムに左右反転する例です。\n",
        "\n",
        "他にも[複数の種類](https://pytorch.org/vision/stable/transforms.html#scriptable-transforms)があります。\n",
        "\n",
        "\n",
        "使用例\n",
        "```\n",
        "transform = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(p=0.5),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEm4qk5GHMaJ"
      },
      "source": [
        "## <練習問題1>\n",
        "\n",
        "上記のCNNにDropoutを追加して、過学習が緩和されたことを確認しましょう。Dropoutは上記コードに追加しても問題ありません。\n",
        "層内の自由な位置に追加して、精度がどのように変化するかを確認しましょう。\n",
        "\n",
        "また、繰返し回数は30以上に設定してください。\n",
        "\n",
        "\n",
        "例:\n",
        "```\n",
        "# 繰り返し回数\n",
        "num_epochs = 30\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc4Dsqa7HMaJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECq1fURMHMaJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_AUHNguHMaJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "J2MVQTtrHMaE",
        "mYMXgttAHMaE",
        "eNt0_LhJ18l1",
        "wKVzBNx5HMaI",
        "YYG8ZRRnHMaI"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "16f3ca604a6cba08719f9b3c138874569df10b281a8f05a95dbbf179e5404e3d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
