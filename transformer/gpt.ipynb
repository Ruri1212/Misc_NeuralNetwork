{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考にしたサイト\n",
    "https://tech.gmogshd.com/transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テキストの文字数 : 1063\n",
      "最初の30文字 :  Head Mounted Displayをはじめとした立体視\n"
     ]
    }
   ],
   "source": [
    "with open('./data.txt','r',encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "print(\"テキストの文字数 :\", len(text))\n",
    "print(\"最初の30文字 : \",text[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '%', '(', ')', '-', '.', '3', 'A', 'C', 'D', 'F', 'G', 'H', 'L', 'M', 'N', 'P', 'S', 'T', 'U', 'Y', '\\\\', 'a', 'b', 'c', 'd', 'e', 'g', 'h'] ['か', 'が', 'き', 'く', 'こ', 'さ', 'し', 'じ', 'す', 'そ', 'た', 'っ', 'つ', 'て', 'で', 'と', 'ど', 'な', 'に', 'の']\n",
      "decode_example: u%-Aaし\n",
      "torch.Size([1063])\n",
      "tensor([13, 27, 23, 26,  1, 15, 35, 40, 34, 39, 27, 26,  1, 10, 30, 38, 36, 32,\n",
      "        23, 43])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 使用されている文字\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars[:30],chars[50:70])\n",
    "# 使用されている文字数\n",
    "char_size = len(chars)\n",
    "\n",
    "# 文字と数字を一対一対応させる辞書\n",
    "char2int = { ch : i for i, ch in enumerate(chars) }\n",
    "int2char = { i : ch for i, ch in enumerate(chars) }\n",
    "\n",
    "# 文字と数字を変換する関数\n",
    "encode = lambda a: [char2int[b] for b in a ]\n",
    "decode = lambda a: ''.join([int2char[b] for b in a ])\n",
    "print(\"decode_example:\",decode([40,2,5,8,23,56]))\n",
    "\n",
    "# テキストファイルを数字にして，tensor型に変換\n",
    "train_data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(train_data.shape)\n",
    "print(train_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_Head(nn.Module):\n",
    "\n",
    "    def __init__(self, n_mbed, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_mbed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_mbed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_mbed, head_size, bias=False)\n",
    "        # 上三角をゼロに，下三角をそのまま\n",
    "        # 大きいサイズの行列\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "\n",
    "    ## channelは文字を表現する次元数\n",
    "    ## Tは文章の長さに相当，足りない部分はpaddingで追加\n",
    "    ## Bはバッチサイズ，長さが違う文章でもmaskすることで対応している\n",
    "    def forward(self, x):\n",
    "        # (Batch_size,data,Channel)\n",
    "        B, T, C = x.shape\n",
    "        print(B,T,C)\n",
    "\n",
    "        k = self.key(x)\n",
    "        print(\"k\",k)\n",
    "        q = self.query(x)\n",
    "        print(\"q\",q)\n",
    "        v = self.value(x)\n",
    "        print(\"v\",v)\n",
    "\n",
    "        #  softmaxの中身計算\n",
    "        wei = q @ k.transpose(-2,-1)*  (C ** -0.5)\n",
    "        print(wei)\n",
    "\n",
    "        # 必要サイズの下三角行列を作成\n",
    "        # 0に相当する部分を-infで置き換える\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        print(wei)\n",
    "        \n",
    "        # 行列の行でsoftmax演算\n",
    "        wei = nn.functional.softmax(wei, dim=-1)\n",
    "        print(wei)\n",
    "\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4166e-02, 9.8583e-01],\n",
      "        [2.4751e-05, 9.9998e-01]], dtype=torch.float64)\n",
      "tensor([[1.4166e-02, 9.8583e-01],\n",
      "        [2.4751e-05, 9.9998e-01]], dtype=torch.float64)\n",
      "tensor([[1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[1.4166e-02,       -inf],\n",
      "        [2.4751e-05, 9.9998e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(4,4))\n",
    "t = 3\n",
    "print(a[:t,:t])\n",
    "print(a[:t,:t]==0)\n",
    "\n",
    "import numpy as np\n",
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "B = np.array([[1,2],[3,4],[5,6]])\n",
    "C = 2\n",
    "\n",
    "\n",
    "D = torch.tensor(A @ B * C ** -0.5)\n",
    "D = nn.functional.softmax(D, dim=-1)\n",
    "\n",
    "\n",
    "print(D)\n",
    "\n",
    "\n",
    "E = torch.tril(torch.ones(2,2))\n",
    "F = D.masked_fill(E == 0,float(\"-inf\"))\n",
    "\n",
    "\n",
    "print(D)\n",
    "print(E)\n",
    "print(F)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print( A @ B * (C ** -0.5) )\n",
    "# print( (A @ B * C) ** -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ホログラフィ]のベクトル表現 : \n",
      " tensor([[ 0.5336, -0.3797, -0.9885,  1.0975, -1.0427],\n",
      "        [-0.8028, -0.0042, -0.7464, -0.4253,  1.4510],\n",
      "        [ 2.6586, -0.7181, -1.0346, -0.2757,  0.9967],\n",
      "        [ 1.2404, -1.5862,  0.3904, -0.0327,  1.3152],\n",
      "        [-0.9889, -0.1633, -0.4732, -0.8290, -0.4769],\n",
      "        [-1.3061, -0.0124, -1.1867, -0.3503, -2.6589]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 6, 5])\n",
      "1 6 5\n",
      "k tensor([[[-0.2808, -0.0104, -0.1705],\n",
      "         [-0.0798,  0.1331, -0.3839],\n",
      "         [-1.2080,  1.4741, -0.1410],\n",
      "         [-1.0363,  1.1063, -0.9143],\n",
      "         [ 0.8121, -0.0276,  0.2819],\n",
      "         [ 1.5220, -0.5073,  0.8169]]], grad_fn=<UnsafeViewBackward0>)\n",
      "q tensor([[[ 0.1264, -0.4882,  0.7203],\n",
      "         [ 0.1389,  0.1589, -0.6315],\n",
      "         [ 1.2587, -0.2302,  0.2275],\n",
      "         [ 0.2006, -0.2484, -0.2871],\n",
      "         [ 0.2695,  0.2588,  0.1622],\n",
      "         [ 0.3580,  0.0847,  1.1614]]], grad_fn=<UnsafeViewBackward0>)\n",
      "v tensor([[[-0.9900,  0.4442,  0.9319],\n",
      "         [ 0.4003, -1.0521, -1.1682],\n",
      "         [-1.1033,  0.7135,  0.3898],\n",
      "         [-0.5340,  0.6870,  0.4841],\n",
      "         [ 0.3697, -0.3559, -0.5418],\n",
      "         [-0.0899,  0.0134,  0.1832]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[-0.0685, -0.1572, -0.4356, -0.5946,  0.1427,  0.4599],\n",
      "         [ 0.0300,  0.1129,  0.0695,  0.2725, -0.0311, -0.1722],\n",
      "         [-0.1743, -0.0977, -0.8461, -0.7902,  0.4887,  0.9921],\n",
      "         [-0.0021,  0.0274, -0.2540, -0.0984,  0.0397,  0.0880],\n",
      "         [-0.0474, -0.0221,  0.0148, -0.0632,  0.1151,  0.1840],\n",
      "         [-0.1339, -0.2072, -0.2108, -0.5989,  0.2754,  0.6488]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[[-0.0685,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.0300,  0.1129,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.1743, -0.0977, -0.8461,    -inf,    -inf,    -inf],\n",
      "         [-0.0021,  0.0274, -0.2540, -0.0984,    -inf,    -inf],\n",
      "         [-0.0474, -0.0221,  0.0148, -0.0632,  0.1151,    -inf],\n",
      "         [-0.1339, -0.2072, -0.2108, -0.5989,  0.2754,  0.6488]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4793, 0.5207, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3860, 0.4168, 0.1972, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2691, 0.2772, 0.2092, 0.2444, 0.0000, 0.0000],\n",
      "         [0.1905, 0.1953, 0.2027, 0.1875, 0.2241, 0.0000],\n",
      "         [0.1393, 0.1295, 0.1290, 0.0875, 0.2098, 0.3048]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9900,  0.4442,  0.9319],\n",
       "         [-0.2660, -0.3350, -0.1617],\n",
       "         [-0.4329, -0.1263, -0.0503],\n",
       "         [-0.5168,  0.1451,  0.1269],\n",
       "         [-0.3512,  0.0727, -0.0024],\n",
       "         [-0.2250,  0.0073,  0.0134]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = 5\n",
    "\n",
    "# [単語数] → [単語数，次元数(vector_size)]\n",
    "embeddings = nn.Embedding(char_size, vector_size)\n",
    "\n",
    "# e.g. ホログラフィをベクトルにする\n",
    "encoded_words = torch.tensor(encode(\"ホログラフィ\"))\n",
    "embeddings_words  = embeddings(encoded_words)\n",
    "print(\"[ホログラフィ]のベクトル表現 : \\n\",embeddings_words)\n",
    "\n",
    "\n",
    "### 次元を揃える\n",
    "embeddings_words = embeddings_words.unsqueeze(dim = 0)\n",
    "print(embeddings_words.shape)\n",
    "\n",
    "## block_sizeは文章の長さよりも長くする必要がある\n",
    "attention_head = SelfAttention_Head(n_mbed=vector_size,head_size=3,block_size=embeddings_words.size(1))\n",
    "attention_head.forward(embeddings_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_MultiHeads(nn.Module):\n",
    "\n",
    "    def __init__(self, n_mbed, num_heads, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList((SelfAttention_Head(n_mbed, head_size, block_size) for _ in range(num_heads)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_mbed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(n_mbed, n_mbed), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
